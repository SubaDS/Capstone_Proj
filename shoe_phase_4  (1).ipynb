{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHOE BRANDS CAPSTONE PROJECT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By Subashree Rajkumar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MACHINE LEARNING MODELS FOR PREDICTION ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression, Ridge, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "import joblib\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(f\"table_all.csv\", index_col=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catagorize the Datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = ['number_of_colors', 'price', 'number_of_sizes', 'reviews', 'comfort', 'quantification']\n",
    "categorical_features = ['category', 'color_1', 'color_2', 'color_3', 'color_4', 'color_5', 'size', 'style_or_product_code']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separate features and labels for price and star rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[numerical_features + categorical_features]\n",
    "y_price = data['price']\n",
    "y_star_rating = data['stars']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_price_train, y_price_test = train_test_split(X, y_price, test_size=0.2, random_state=42)\n",
    "X_train, X_test, y_star_rating_train, y_star_rating_test = train_test_split(X, y_star_rating, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Prediction Model for PRICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Various Machine learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(),\n",
    "    'Random Forest Regressor': RandomForestRegressor(),\n",
    "    'Gradient Boosting Regressor': GradientBoostingRegressor()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression has the RMSE of 45.83657523273772\n",
      "Ridge Regression has the RMSE of 72.67207973134293\n",
      "Random Forest Regressor has the RMSE of 159.6038770969396\n",
      "Gradient Boosting Regressor has the RMSE of 74.08400970446675\n"
     ]
    }
   ],
   "source": [
    "best_price_model = None\n",
    "best_price_rmse = float('inf')\n",
    "\n",
    "\n",
    "for name, model in price_models.items():\n",
    "    price_model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('regressor', model)])\n",
    "    price_model.fit(X_train, y_price_train)\n",
    "    predictions = price_model.predict(X_test)\n",
    "    rmse = mean_squared_error(y_price_test, predictions, squared=False)\n",
    "    \n",
    "    if rmse < best_price_rmse:\n",
    "        best_price_rmse = rmse\n",
    "        best_price_model = price_model\n",
    "        best_price_model_name = name\n",
    "    \n",
    "    print(f\"{name} has the RMSE of {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Price Prediction Model and Perform hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Price Prediction Model: Linear Regression\n",
      "Best Price Prediction RMSE: 45.83657523273772\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Price Prediction Model:\", best_price_model_name)\n",
    "print(\"Best Price Prediction RMSE:\", best_price_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Linear Regression:  {'model__fit_intercept': True}\n",
      "Best Linear Regression model has the RMSE of 45.83657523273772\n",
      "Best parameters for Ridge Regression:  {'model__alpha': 0.1}\n",
      "Best Ridge Regression model has the RMSE of 48.77537829334586\n",
      "Best parameters for Random Forest Regressor:  {'model__max_depth': 10, 'model__min_samples_split': 2, 'model__n_estimators': 100}\n",
      "Best Random Forest Regressor model has the RMSE of 159.06485468787565\n",
      "Best parameters for Gradient Boosting Regressor:  {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__n_estimators': 100}\n",
      "Best Gradient Boosting Regressor model has the RMSE of 47.65333844470699\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "# Define the models and their parameters\n",
    "price_models = {\n",
    "    'Linear Regression': [LinearRegression(), {'fit_intercept': [True, False]}],\n",
    "    'Ridge Regression': [Ridge(), {'alpha': [0.1, 0.5, 1, 5, 10]}],\n",
    "    'Random Forest Regressor': [RandomForestRegressor(), {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20, 30], 'min_samples_split': [2, 5, 10]}],\n",
    "    'Gradient Boosting Regressor': [GradientBoostingRegressor(), {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 1], 'max_depth': [3, 5, 8]}]\n",
    "}\n",
    "\n",
    "# Perform hyperparameter tuning and calculate RMSE for each model\n",
    "for model_name, [model, params] in price_models.items():\n",
    "    # Create a pipeline that combines the preprocessor with the model\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', model)])\n",
    "    \n",
    "    # Create a new param grid for the pipeline\n",
    "    param_grid = {f'model__{key}': value for key, value in params.items()}\n",
    "    \n",
    "    # Perform hyperparameter tuning\n",
    "    grid = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "    grid.fit(X_train, y_price_train)\n",
    "    \n",
    "    # Use the best model to predict on the test set\n",
    "    best_preds = grid.predict(X_test)\n",
    "    \n",
    "    # Calculate RMSE for the best model\n",
    "    best_rmse = sqrt(mean_squared_error(y_price_test, best_preds))\n",
    "    \n",
    "    # Print the best parameters and RMSE for each model\n",
    "    print(f\"Best parameters for {model_name}: \", grid.best_params_)\n",
    "    print(f\"Best {model_name} model has the RMSE of {best_rmse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the predicted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_price_model.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('model', LinearRegression())])\n",
    "param_grid = {f'model__fit_intercept': True}\n",
    "\n",
    "grid = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "joblib.dump(grid, 'best_price_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INfERANCE\n",
    "=======\n",
    "These RMSE values represent the average deviation of predicted values from the actual values. Lower RMSE values indicate better performance.\n",
    "\n",
    "For the price prediction, an RMSE of 45.84 suggests that, on average, the predicted prices differ from the actual prices by approximately $45.84.\n",
    "\n",
    "The best performing model is the Linear regression model with a RMSE  of approximately 46%. The scores for both the training and testing data were similar, reducing concerns of the model being overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Prediction Model for  Star Rating "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"table_all.csv\", index_col=None)\n",
    "import numpy as np\n",
    "for column in df.columns:\n",
    "    if df[column].dtype == object:\n",
    "        df[column].fillna(df[column].mode()[0], inplace=True)\n",
    "    else:\n",
    "        df[column].fillna(df[column].mean(), inplace=True)\n",
    "\n",
    "le = LabelEncoder()\n",
    "for column in df.columns:\n",
    "    if df[column].dtype == object:\n",
    "        df[column] = le.fit_transform(df[column])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "for column in df.columns:\n",
    "    if df[column].dtype == np.int64 or df[column].dtype == np.float64:\n",
    "        df[column] = scaler.fit_transform(df[column].values.reshape(-1, 1))\n",
    "\n",
    "X = df.drop('stars', axis=1)\n",
    "y = df['stars']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression has the RMSE of 0.6366255102881898\n",
      "Random Forest has the RMSE of 0.19705565455960955\n",
      "Gradient Boosting Tree has the RMSE of 0.1820685375959569\n"
     ]
    }
   ],
   "source": [
    "# Train models\n",
    "# Linear Regression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Gradient Boosting Tree\n",
    "gbt = GradientBoostingRegressor(random_state=42)\n",
    "gbt.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "lr_preds = lr.predict(X_test)\n",
    "rf_preds = rf.predict(X_test)\n",
    "gbt_preds = gbt.predict(X_test)\n",
    "\n",
    "lr_rmse = mean_squared_error(y_test, lr_preds, squared=False)\n",
    "rf_rmse = mean_squared_error(y_test, rf_preds, squared=False)\n",
    "gbt_rmse = mean_squared_error(y_test, gbt_preds, squared=False)\n",
    "\n",
    "print(f\"Linear Regression has the RMSE of {lr_rmse}\")\n",
    "print(f\"Random Forest has the RMSE of {rf_rmse}\")\n",
    "print(f\"Gradient Boosting Tree has the RMSE of {gbt_rmse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Linear Regression:  {'fit_intercept': True}\n",
      "Best parameters for Random Forest:  {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Best parameters for Gradient Boosting Tree:  {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the hyperparameters and their values\n",
    "lr_params = {'fit_intercept': [True, False]}\n",
    "rf_params = {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20, 30], 'min_samples_split': [2, 5, 10]}\n",
    "gbt_params = {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 1], 'max_depth': [3, 5, 8]}\n",
    "\n",
    "# Perform hyperparameter tuning on Linear Regression\n",
    "lr_grid = GridSearchCV(lr, lr_params, cv=5, scoring='neg_mean_squared_error')\n",
    "lr_grid.fit(X_train, y_train)\n",
    "\n",
    "# Perform hyperparameter tuning on Random Forest\n",
    "rf_grid = GridSearchCV(rf, rf_params, cv=5, scoring='neg_mean_squared_error')\n",
    "rf_grid.fit(X_train, y_train)\n",
    "\n",
    "# Perform hyperparameter tuning on Gradient Boosting Tree\n",
    "gbt_grid = GridSearchCV(gbt, gbt_params, cv=5, scoring='neg_mean_squared_error')\n",
    "gbt_grid.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best parameters for Linear Regression: \", lr_grid.best_params_)\n",
    "print(\"Best parameters for Random Forest: \", rf_grid.best_params_)\n",
    "print(\"Best parameters for Gradient Boosting Tree: \", gbt_grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Linear Regression model has the RMSE of 0.6366255102881898\n",
      "Best Random Forest model has the RMSE of 0.19582583194183356\n",
      "Best Gradient Boosting Tree model has the RMSE of 0.18044048049973138\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "# Use the best models to predict on the test set\n",
    "lr_best_preds = lr_grid.predict(X_test)\n",
    "rf_best_preds = rf_grid.predict(X_test)\n",
    "gbt_best_preds = gbt_grid.predict(X_test)\n",
    "\n",
    "# Calculate RMSE for the best models\n",
    "lr_best_rmse = sqrt(mean_squared_error(y_test, lr_best_preds))\n",
    "rf_best_rmse = sqrt(mean_squared_error(y_test, rf_best_preds))\n",
    "gbt_best_rmse = sqrt(mean_squared_error(y_test, gbt_best_preds))\n",
    "\n",
    "# Print RMSE for the best models\n",
    "print(f\"Best Linear Regression model has the RMSE of {lr_best_rmse}\")\n",
    "print(f\"Best Random Forest model has the RMSE of {rf_best_rmse}\")\n",
    "print(f\"Best Gradient Boosting Tree model has the RMSE of {gbt_best_rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Price Prediction Model: Gradient Boosting Tree\n",
      "Best Price Prediction RMSE: 0.18044048049973138\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Price Prediction Model: Gradient Boosting Tree\")\n",
    "print(\"Best Price Prediction RMSE:\", gbt_best_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_star_rating_model.pkl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(gbt_best_rmse, 'best_star_rating_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inferance\n",
    "=========\n",
    "\n",
    "Regarding star rating prediction \n",
    "\n",
    "The best performing model is the Gradient boosting Tree with an RMSE of 0.180 suggests that, on average, the predicted star ratings differ from the actual star ratings by approximately 0.180 stars\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
